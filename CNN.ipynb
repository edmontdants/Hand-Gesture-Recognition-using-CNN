{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in Eager mode.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "try:\n",
    "  tf.enable_eager_execution()\n",
    "  print('Running in Eager mode.')\n",
    "except ValueError:\n",
    "  print('Already running in Eager mode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: (10, 10, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a random colour \"image\" of shape 10x10 with a depth of 3 (for red, green and blue)\n",
    "dummy_input = np.random.uniform(size=[10, 10, 3])\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.imshow(dummy_input)\n",
    "ax.grid(False)\n",
    "print('Input shape: {}'.format(dummy_input.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output dimension is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[9, 9, 3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Convolutional layer parameters {run: \"auto\"}\n",
    "filters = 3  #@param { type: \"slider\", min:0, max: 10, step: 1 }\n",
    "kernel_size = 2 #@param { type: \"slider\", min:1, max: 10, step: 1 }\n",
    "stride = 1 #@param { type: \"slider\", min:1, max: 3, step: 1 }\n",
    "\n",
    "conv_layer = tf.keras.layers.Conv2D(\n",
    "    filters=filters, \n",
    "    kernel_size=kernel_size, \n",
    "    strides=stride,\n",
    "    padding=\"valid\",\n",
    "    input_shape=[10, 10, 3])\n",
    "\n",
    "# Convert the image to a tensor and add an extra batch dimension which\n",
    "# the convolutional layer expects.\n",
    "input_tensor = tf.convert_to_tensor(dummy_input[None, :, :, :])\n",
    "convoluted = conv_layer(input_tensor)\n",
    "\n",
    "print('The output dimension is:')\n",
    "list([d.value for d in convoluted.shape])[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9, 5, 8],\n",
       "       [9, 9, 8],\n",
       "       [9, 9, 9]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#@title Answer { display-mode: \"form\" }\n",
    "X = np.array([[9, 5, 4, 5, 6, 4],\n",
    "              [6, 6, 3, 5, 8, 2],\n",
    "              [4, 6, 9, 1, 3, 6],\n",
    "              [9, 7, 1, 5, 8, 1],\n",
    "              [4, 9, 9, 5, 7, 3],\n",
    "              [7, 3, 6, 4, 9, 1]])\n",
    "\n",
    "max_pool_layer = tf.keras.layers.MaxPooling2D((2, 2), strides=2)\n",
    "max_pool_layer(tf.convert_to_tensor(X[None, :, :, None])).numpy().squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 7867s 46us/step\n"
     ]
    }
   ],
   "source": [
    "cifar = tf.keras.datasets.cifar10\n",
    "(train_images, train_labels), (test_images, test_labels) = cifar.load_data()\n",
    "cifar_labels = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
